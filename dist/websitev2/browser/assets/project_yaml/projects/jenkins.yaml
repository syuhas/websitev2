- id: jenkins
  title: Jenkins Pipeline - Dynamic Cloud Node Provisioning with AWS
  subtitle: Fully automated build pipeline with dynamically provisioned cloud node to push containterized applications to AWS.
  github: https://github.com/syuhas/jenkinsTest
  description: |
    Utilizing Jenkins to build and deploy Docker images to AWS ECS using dynamically provisioned EC2 build nodes to save cost on idle servers.
  listIcon: /assets/project-images/jenkins-images/jenkins_icon.png
  titleIcons:
    - /assets/project-images/jenkins-images/jenkins_icon.png
    - /assets/project-images/jenkins-images/jenkins_icon3.png
    - /assets/project-images/jenkins-images/jenkins_icon2.png
  sections:
    - title: Overview
      tabTitle: Overview
      subsections:
        - content: |

          imgs:
            - /assets/project-images/jenkins-images/jenkinsDocker.png

        - content: |
            For this project I wanted to delve into the popular CI/CD pipeline tool Jenkins and explore the benefits of using cloud computing to save on cost and resource usage. I created a simple Python Flask skeleton application to be containerized on Docker and my goal was to have Jenkins fully automate the process from the initial git push from my local machine all the way up to building and pushing the image to AWS ECR to be run as a task on ECS. To fully take advantage of the agility and speed of cloud computing as well as the ‘pay as you go’ philosophy behind cost savings, I wanted to only have a build server provisioned when I needed it. This way I am not running unnecessary idle servers, I can scale to multiple build nodes as needed in minutes and can benefit on the cost savings of only using the resources I need, when I need them. <br><br>

            Much of the challenge of a project like this is configuration of authorization and integration between services. This task is made much easier through the use of Jenkins plugins that allow for easier storing and usage of credentials. In this project review I will go over all of the configuration needed to automate the pipeline and highlight all of the features I took advantage of to achieve the end result.
          imgs:
    - title: Jenkins Master and Plugins
      tabTitle: Jenkins Master
      subsections:
        - content: |
            To run and configure all of the build jobs, I set up a master Jenkins server on an AWS EC2 instance. The server is routed through my domain at digitalsteve.net and behind a load balancer for HTTPS encryption and an Elastic IP address.
          imgs:
            - /assets/project-images/jenkins-images/master1.png
        - content: |
            The main plugins used for this project are:
          listItems:
            - Amazon EC2
            - Cloudbees AWS Credentials
            - Credentials
            - GitHub
            - Pipeline
            - SSH Credentials
          imgs:
            - /assets/project-images/jenkins-images/master2.png
            - /assets/project-images/jenkins-images/master3.png
    - title: GitHub Integration
      tabTitle: GitHub
      subsections:
        - content: |
            The first step of GitHub integration requires enabling a PAT(Personal Access Token) to be used on the Jenkins master server to allow Jenkins to use the GitHub API. This will allow Jenkins to clone my repository on my build node for the SCM checkout phase.
          imgs:
            - /assets/project-images/jenkins-images/git1.png
            - /assets/project-images/jenkins-images/git2.png
        - content: |
            Next, I set up a Webhook on GitHub that allows push notifications to flow downstream to Jenkins and trigger a pipeline job after my code updates are committed. Later, I will go over using the credentials when configuring a job and enabling the Webhook to push code from GitHub to Jenkins to trigger the pipeline to run.

            For the payload url I simply need to append /github-webhook/ to the end of my master server url to allow the Webhook to push code to Jenkins with the GitSCM polling trigger enabled.

            I also generated an API token for my username to secure the webhook to my account. This is then entered as the Webhook secret.
    - title: Python Application Configuration
      tabTitle: Python App
      subsections:
        - content: |
            I chose to use a simple Python Flask skeleton application to run through the pipeline to test out the functionality for demo purposes. The application will be run on a Docker container after building the image on the Jenkins build server and pushing the image to ECR to run as an ECS task.
          imgs:
            - /assets/project-images/jenkins-images/py1.png
            - /assets/project-images/jenkins-images/py2.png
        - content: |

          imgs:
            - /assets/project-images/jenkins-images/py3.png
            - /assets/project-images/jenkins-images/py4.png
    - title: AWS Integration
      tabTitle: AWS
      subsections:
        - content: |
            Correct AWS integration is the most important portion of the setup for this pipeline. Jenkins needs to be able to interact with AWS via the AWS CLI to provision servers, SSH into the dynamically provisioned cloud server to manipulate the EC2 instance OS, and ultimately push the Docker image to ECR. This is also the stage where the 'least privilege' principle is important to keep in mind as sensitive credentials will be passed through the server. Here I am using the Cloudbees EC2 plugin to securely input public/Secret access keys and SSH key pair credentials. For this project, I am granting more privileges than necessary. In production, a privilege analysis should be done to determine the least amount of authorization to run the pipeline.<br><br>

            First, I generated public and private access keys for my user and entered the credentials via the Cloudbees plugin.<br><br>

            I also attached an AWS role to the credentials which will be used for AWS services provisioning and pushing images to ECR which is described below.
          imgs:
            - /assets/project-images/jenkins-images/aws1.png
            - /assets/project-images/jenkins-images/aws2.png
        - content: |
            This is the role used for the AWS credentials in Jenkins.
            I have attached custom policies to the role, allowing the provisioned EC2 instance to:
          listItems:
            - Get an STS authorization token for pushing the Docker image to ECR
            - Giving the slave node server access to EC2 functionality
            - Allowing the slave node server to update the ECS service with the latest image
          imgs:
            - /assets/project-images/jenkins-images/aws3.png
            - /assets/project-images/jenkins-images/aws4.png
        - content: |
            In addition to the access keys and attached policies, the slave node will need to SSH into the instance to update and configure the OS and dependencies. This will allow Jenkins to run the init script and pass the AWS credentials to the Jenkinsfile pipeline script.
          imgs:
            - /assets/project-images/jenkins-images/aws5.png
    - title: ECR Permissions
      tabTitle: Permissions
      subsections:
        - content: |
            In order to allow the newly provisioned node to push the new image to ECR, permissions must be attached to the instance profile role.
        - content: |
            This will define the role's permission set for performing actions on the ECR repository.
          imgs:
            - /assets/project-images/jenkins-images/ecr1.png
        - content: |
            For demo purposes, I gave the instance profile role full rights to the ECR service for testing, but I can go back and redefine the permissions set to grant only the needed permissions for the tasks required in the pipeline.
          imgs:
            - /assets/project-images/jenkins-images/ecr2.png
    - title: Dynamically Provisioned EC2 Worker Node
      tabTitle: Worker Node
      subsections:
        - content: |
            Now that I have all of the necessary credentials configured and the permissions and policies defined, I can configure a template for dynamically provisioning new slave build nodes. The benefit of having servers spin up only when I need them is that these build nodes will only exist when the pipeline runs. After the idle timeout, the server will be automatically decommissioned until I need to run the pipeline again. Configuring this automation upfront really shows the power of cloud computing from a cost-savings perspective. Now, I will only ever need to have one minimal master node running for my Jenkins server when no jobs are running.
        - content: |
            First, I will use the AWS access keys with the attached IAM instance profile role and SSH key pair to authorize Jenkins to connect to AWS and then SSH into the newly created EC2 instance.
          imgs:
            - /assets/project-images/jenkins-images/cloud1.png
            - /assets/project-images/jenkins-images/cloud2.png
        - content: |
            I then need to define an AMI ID to indicate what type of instance I would like for Jenkins to spin up on my behalf. I also need to indicate which region my availability zones my instance can be created in as well as an instance type and size. I have already configured a security group with the necessary ports exposed (22, 8080, 80, 443) to allow for necessary inbound and outbound traffic to flow through my instance. I then tell Jenkins to attach that security group to each new node.
          imgs:
            - /assets/project-images/jenkins-images/cloud3.png
            - /assets/project-images/jenkins-images/cloud4.png
        - content: |
            I can now indicate which root folder for Jenkins to use to set up a temporary workspace that will act as the base of operations where my repository will be cloned and the Docker image can be built from. I am using a Unix type AMI, and will be allowing an SSH connection on port 22.

            I can then define how this node should be used. Since I only want Jenkins to spin up these nodes when needed, I set the built-in node to operate at 0, and have indicated this node configuration to be used as much as possible. This means that only dynamically provisioned nodes will be used for any type of job.
          imgs:
            - /assets/project-images/jenkins-images/cloud5.png
            - /assets/project-images/jenkins-images/cloud6.png
        - content: |
            Any additional setup not indicated by the plugin settings needs to be configured with the use of an init script, which will contain important directions for the new instance.

            The init script will:
          listItems:
            - Update the OS
            - Install Docker and add the remote user to the Docker group
            - Create, change permissions for, and add the remote user to the new Jenkins root folder
            - Change permission of the Docker service to allow the remote user to run Docker without the sudo command
          imgs:
            - /assets/project-images/jenkins-images/cloud7.png
            - /assets/project-images/jenkins-images/cloud8.png
        - content: |
            Finally, I just need to configure a few small connection settings and I can now spin up a dynamically provisioned node only when I need it.
          imgs:
            - /assets/project-images/jenkins-images/cloud9.png
    - title: Jenkinsfile & Dockerfile
      tabTitle: Jenkins/Dockerfile
      subsections:
        - content: |
            For this application, I am using a Jenkinsfile to write my pipeline build script.

            In the script, the first stage will build and publish the Docker image to ECR. This is where the access keys, attached STS identity policy and ECS policy come into play. This will allow the script to get a temporary login password to push the new image to ECR.<br><br>

            Next, the script will list the images on the repository. This will confirm that the push to ECR was successful.<br><br>

            Once the new image has been pushed to the repository, the script will now update the ECS cluster to run the new task on the ECS service. The number of tasks can be changed based on the use case, but for demo purposes I have set my task value to 1.<br><br>

            Finally, the script will wipe all Docker images or running containers from the server, allowing for a clean build if I need to run builds in close proximity.
        - content: |
            This will define the role's permission set for performing actions on the ECR repository.
          imgs:
            - /assets/project-images/jenkins-images/jd1.png
        - content: |
            For my Dockerfile, I simply need to pull a base python Docker image, set my working directory, and then copy and install my dependencies as defined in my requirements file.<br><br>

            I now can run the Flask application on a Gunicorn server on port 80 to allow inbound HTTP traffic. As long as I configure the ECS service to expose port 80 from within Docker, I will be able to access the task from a browser to view my application.
          imgs:
            - /assets/project-images/jenkins-images/jd2.png
    - title: Pipeline Job Configuration
      tabTitle: Pipeline
      subsections:
        - content: |
            With all of the scripts and code written and all of the authentication and configuration finished, I can now set up a new pipeline job to actually run the pipeline. I will be choosing a single branch pipeline for the purposes of this project as I will not need to be managing multiple build branches for such a simple application.
          imgs:
            - /assets/project-images/jenkins-images/pipe1.png
        - content: |
            The goal is to trigger the pipeline when I commit new code to my remote repository. I can now use the GitHub Webhook and Personal Access Token that I set up earlier to ensure this happens with every push I make to the repository. Once the pipeline is triggered from the Webhook, Jenkins will push the new code to each newly provisioned slave instance node. This will then allow Docker to build the image based on each new checkout from the repository.
          imgs:
            - /assets/project-images/jenkins-images/pipe2.png
            - /assets/project-images/jenkins-images/pipe3.png
        - content: |
            Jenkins will pull code from the main branch. I also need to specify the scripting that Jenkins will use. Here, I tell Jenkins to use the Jenkinsfile located at the base of my workspace directory. With all of the pieces in place, I will now able to run my pipeline which will use all of the automation to dynamically spin up a server to build my project.
          imgs:
            - /assets/project-images/jenkins-images/pipe4.png
    - title: Final Steps and Running the Pipeline
      tabTitle: Final Steps
      subsections:
        - content: |
            I can now run my pipeline automation. My pipeline will be triggered from my GitHubSCM Webhook. Jenkins will spin up a slave build node, build my Docker image, push the image to ECR, display the images on my repository, and finally update my ECS service with the latest image from the repository.<br><br>

            This can all be done by simply committing new code to my remote repository.<br><br>

            Jenkins will automate the entire process as soon as it receives the trigger.
          imgs:
            - /assets/project-images/jenkins-images/fin1.png
        - content: |
            Additionally, I can spin up a pre-configured slave node manually if I want to have the server running ahead of time. This is optional as the build server will be provisioned either way if I do not manually start the server.
          imgs:
            - /assets/project-images/jenkins-images/fin2.png
        - content: |
            Once the SCM Webhook is triggered, Jenkins will check for available build nodes. Since the previous node has been decommissioned, Jenkins will now tell AWS to spin up a fresh Jenkins server that is completely configured with credentials and instructions to be able to build and push my application.
          imgs:
            - /assets/project-images/jenkins-images/fin3.png
            - /assets/project-images/jenkins-images/fin4.png
        - content: |
            Here, we can see a bit of what is happening in the background. Jenkins is attempting to SSH into the newly created server and run the init script. The Jenkins node will be configured with its own Jenkins dependencies, and will then install the dependencies defined in the init script. Once the script is finished running, Jenkins will check to make sure the proper number of defined build nodes are online and then proceed to run the pipeline.
          imgs:
            - /assets/project-images/jenkins-images/fin5.png
            - /assets/project-images/jenkins-images/fin6.png
        - content: |
            Jenkins will now proceed to run the pipeline after it has a configured slave node up and running.
          imgs:
            - /assets/project-images/jenkins-images/fin7.png
            - /assets/project-images/jenkins-images/fin8.png
        - content: |
            The ECS service has been successfully updated and I can now connect to the newly created task in the service.
          imgs:
            - /assets/project-images/jenkins-images/fin9.png
            - /assets/project-images/jenkins-images/fin10.png
        - content: |
            To test that the ports were properly configured, I can simply visit the site in the browser through the task public DNS or public IP after the pipeline completes and the new service updates.
          imgs:
            - /assets/project-images/jenkins-images/fin11.png
        - content: |
            Now that the pipeline has run and my new task is running on ECS, an idle timeout will have the instance self-terminate. The idle timeout is 30 minutes so the same process will be repeated each time new code is committed outside of the idle window. Otherwise, Jenkins will use an existing node if it is still in service.
    - title: Summary
      tabTitle: Summary
      subsections:
        - content: |
            This project has made Jenkins my new favorite tool by far. It encompasses all the things that I love about cloud computing and DevOps. Integration, automation, containerization, dynamic provisioning of resources, and a ‘pay-as-you-go’ philosophy that makes cloud so innovative and interesting. I had a great time learning the ins and outs of Jenkins and the possibilities it presents with automating any task you can think of when paired with AWS.<br><br>

            My favorite aspect of this project was the automation for sure. When you do all the work up front and just watch it work, it really is that feeling of efficiency and preparation that makes CI/CD so interesting and fulfilling to me. I will be implementing Jenkins in more of my projects in the future and I have learned many useful tools while creating this project.<br><br>

            Integrating AWS and Jenkins really shows the power of cloud integration and automation and really inspires me to explore more of the possibilities that are present when combining powerful tools like this. I learned a lot doing this project and was very happy with the result. I look forward to hearing your reactions to the project and I sincerely hope you enjoyed this dive into the world of Jenkins.
          imgs:
